#below are examples of code used to generate the MAGs and perform the KO, PFAM, and taxonomic annotation and dn/ds analysis.

#quality control. First trim with fastp and then remove potential contaminants.

fastp -i sample_R1.fastq -I sample_R2.fastq -o sample_R1.trimmed.fastq -O sample_R2.trimmed.fastq
bbsplit.sh in1=sample_R1.trimmed.fastq in2=sample_R2.trimmed.fastq ref=GRCh38.p13.genome.fa,NC_001422.1.fa,GRCm38.p6.genome.fa basename=out_%.fq outu1=sample_clean_R1.fq outu2=sample_clean_R2.fq

#assemble using megahit

megahit -1  sample_clean_R1.fq -2 sample_clean_R2.fq -o /Megahit/sample/ 
cd /Megahit/sample
mkdir metabat
bowtie2-build final.contigs.fa megahit-contigs-bowtie2-index
bowtie2 -x megahit-contigs-bowtie2-index -1 sample_clean_R1.fq -2 sample_clean_R2.fq -S sample.sam
samtools view -bS sample.sam > sample.bam
samtools sort sample.bam -o sample.sorted.bam
jgi_summarize_bam_contig_depths --outputDepth sample.depth.txt --pairedContigs sample.paired.txt sample.sorted.bam
metabat2 -i final.contigs.fa -o /Megahit/sample/metabat/samplebins -a sample.depth.txt


#refinem to remove outliers
samtools index sample.sorted.bam
refinem scaffold_stats final.contigs.fa metabat scaffold_stats_out sample.sorted.bam
refinem outliers scaffold_stats_out/scaffold_stats.tsv outlier_output_dir
refinem filter_bins metabat outlier_output_dir/outliers.tsv bins_without_outliers_via_genomic_content

#checkm to summarize MAGs
checkm lineage_wf bins_without_outliers_via_genomic_content lineage_wf_out_post_refinem 
checkm qa lineage_wf_out_post_refinem_new2/lineage.ms lineage_wf_out_post_refinem_new2 -o 2 -f sampleqa_postrefinement.tsv --tab_table



#then dereplicate (need to ensure the .fna files that you wish to dereplicate are in a single directory)
dRep dereplicate -p 60 -sa 0.965 dRep_outout_directory_96_5 -g ./genomedirectory/*fna


#taxonomic annotations/tree
gtdbtk classify_wf --genome_dir /dRep_outout_directory_96_5/dereplicated_genomes --extension fna --out_dir gtdbtk_output_post_dRep_96_5

#annotate
enrichm annotate --verbosity 5 --output enrichmannotateout_ko --genome_directory /dRep_outout_directory_96_5/dereplicated_genomes --ko --threads 48  --parallel 48
interproscan.sh -appl Pfam -i sample.faa -f TSV,GFF3  -goterms  -iprlookup -iprscan --output-dir interproscanout  

#coverrm
coverm genome --genome-fasta-directory /gpfs/scratch/jbkelly/Megahit/dRep_output_genoems_clone/ --mapper bwa-mem -t 80 -c /sample1_R1.fq /sample2.fq /rawreads/jk18x1bz_clean_R1.fq /rawreads/jk18x1bz_clean_R2.fq /rawreads/jk18x22_clean_R1.fq /rawreads/jk18x22_clean_R2.fq /rawreads/jk18x25_clean_R1.fq /rawreads/jk18x25_clean_R2.fq /rawreads/jk18x27_clean_R1.fq /rawreads/jk18x27_clean_R2.fq /rawreads/jk18x34_clean_R1.fq /rawreads/jk18x34_clean_R2.fq /rawreads/jk18x40_clean_R1.fq /rawreads/jk18x40_clean_R2.fq /rawreads/jk18x44_clean_R1.fq /rawreads/jk18x44_clean_R2.fq /rawreads/jk18x7_clean_R1.fq /rawreads/jk18x7_clean_R2.fq /rawreads/jk18x8_clean_R1.fq /rawreads/jk18x8_clean_R2.fq /rawreads/jk18x9_clean_R1.fq /rawreads/jk18x9_clean_R2.fq /rawreads/jk18xA_clean_R1.fq /rawreads/jk18xA_clean_R2.fq /rawreads/p16x33_clean_R1.fq /rawreads/p16x33_clean_R2.fq /rawreads/p16x34_clean_R1.fq /rawreads/p16x34_clean_R2.fq /rawreads/p16x43_clean_R1.fq /rawreads/p16x43_clean_R2.fq /rawreads/p16x44_clean_R1.fq /rawreads/p16x44_clean_R2.fq /rawreads/p16x57_clean_R1.fq /rawreads/p16x57_clean_R2.fq /rawreads/p16x60_clean_R1.fq /rawreads/p16x60_clean_R2.fq /rawreads/p16x63_clean_R1.fq /rawreads/p16x63_clean_R2.fq /rawreads/p16x65_clean_R1.fq /rawreads/p16x65_clean_R2.fq --bam-file-cache-directory /gpfs/scratch/jbkelly/Megahit/bamcachederep  > covermoutputFullMagSet.txt 2>&1


#dn/ds analysis

#we grepped out the KO gene annotations from the .fna files with the nucleotide sequence of the reading frames (in the output directory 'genome_genes' generated by enrichm)

#the 'listofKO.txt' file is simply the KO accessions (i.e. K00001, K00003, K00004, etc.), one per line.

for i in *.fna; 
do
while read p; do
gene=$(echo "$p")
grep -A2 ${gene} $i | head -2 >> ${gene}.fna
done <listofKO.txt
done

#the three core genes of CSGs were manually extracted using the .gff and .fna files of the enrichm outputs.

#then ran transdecoder on the .fna files of the lists of genes
for file in *.fna; do
    TransDecoder.LongOrfs -m 50 -t $file;
    TransDecoder.Predict --no_refine_starts --single_best_only -t $file;
    sed -i 's/\(>[a-zA-Z0-9:_.-]\+\).p[0-9].*/\1/'  ${file}.transdecoder.cds;
done

#then translator x
for i in K17*.fna.transdecoder.cds;
do
translatorx -i $i -p F -c 11 -o ${i}_translatorx.
done


#then run parallel_IQ-tree.py

#convert alignments to phylip format using pxs2phy program in phyx (https://github.com/FePhyFoFum/phyx/)

#then run codeml_parallel.py
